

<!DOCTYPE html>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<!-- referred from Feng Gao http://feng-gao.cn/  -->
<meta name="keywords" content="AI Security Group (AISec), OUC, Yuezun Li, Junyu Dong">
<meta name="description" content="AI Security Group (AISec)">
<link rel="stylesheet" href="./jemdoc.css" type="text/css">
<title>AI Security Group (AISec) @ OUC</title>

<!-- CSS  -->
<link href="../materialize.min.css" type="text/css" rel="stylesheet" media="screen,projection">
<link href="../aos.css" type="text/css" rel="stylesheet" media="screen,projection">
<link href="../style.css" type="text/css" rel="stylesheet" media="screen,projection">

<!-- Place your kit's code here -->
<script src="https://kit.fontawesome.com/fed508a68e.js" crossorigin="anonymous"></script>


<style>
div.noshow { display: none; }
div.bibtex {
	margin-right: 10%;
	margin-top: 1em;
	margin-bottom: 1em;
	padding: 0.2em 0.5em;
	background: #F8F9F9;
}
div.bibtex pre { font-family: Georgia, Times, Arial; font-size: 85%; overflow: auto;  width: 100%; padding: 0em 0em;}


div.gallery {
  margin: 5px;
  border: 1px solid #ccc;
  float: left;
  width: 150px;
}

div.gallery:hover {
  border: 1px solid #777;
}

div.gallery img {
  width: 100%;
  height: 160px;
}

div.desc {
  padding: 0px;
  text-align: center;
}


</style> 

<script type="text/javascript">
    <!--
    // Toggle Display of BibTeX
    function toggleBibtex(articleid) {
        var bib = document.getElementById('bib_'+articleid);
        if (bib) {
            if(bib.className.indexOf('bibtex') != -1) {
                bib.className.indexOf('noshow') == -1?bib.className = 'bibtex noshow':bib.className = 'bibtex';
            }
        } else {
            return;
        }
    }
-->
</script>

</head>
<body data-aos-easing="ease" data-aos-duration="400" data-aos-delay="0">


<div class="row container"><div class="row"><br>
<div class="title">Welcome to AI Security Group (AISec) @ OUC</div><hr>
<table>
	<tbody>
		<tr>
            <img src="./data/teaser.jpg" border="0" width="100%">
		</tr>
    </tbody>
</table>
</div></div>
	
<!-- [<a href="#Biography">Biography</a> | <a href="#News">News</a> | <a href="#Experience">Experience</a> | <a href="#Preprints">Preprints</a> | <a href="#Publications">Publications</a> | <a href="#Projects">Projects</a> | <a href="#Talks">Talks</a> | <a href="#Service">Service</a>]</p> -->

<!--==========================================
                    AI Security Group
===========================================-->
<div class="row container"><div class="row"><br>
<div class="title">AI Security Group (AISec)<img src="./data/AISec.png" width="6%"></div><hr>
<!-- <h2>AI Security Group (AISec)</h2> -->
<p>
AI Security Group (AISec) is an interdisciplinary research group under the institute of Artificial Intelligence, Ocean University of China, led by <a href="http://ai-ouc.cn/faculty/dongjy.html">Prof. Junyu Dong</a> and <a href="https://yuezunli.github.io/">Dr. Yuezun Li</a>. 
Our group focuses on defending the newly raised security threats introduced by advanced Artificial Intelligence (AI) technologies, such as 
falsified multimedia (e.g., DeepFakes), the vulnerability of DNN models.
</p>
</div></div>

<div class="row container"><div class="row"><br>
<div class="title">Why is AI Security important?</div><hr>
<!-- <h2>Why is AI Security important?</h2> -->

<table>
    <tbody>
        <tr>
            <td style="width:45%; vertical-align: top;">
                <i class="fas fa-bookmark"></i> 
                The falsified multimedia (<a href="https://zh.wikipedia.org/wiki/Deepfake">DeepFake</a>) can mislead the public opinion by forging victim's activities that do not happen in reality, which
                will potientially raise the societal risk, e.g., making revenge porngraphic videos [<a href="https://www.bbc.com/news/technology-42912529">Here</a>] or inflammetory comments of public figures 
                [<a href="https://www.howtogeek.com/682865/audio-deepfakes-can-anyone-tell-if-they-are-fake/">Here</a>].
            </td>

            <td style="width:45%; vertical-align: top;">
                <i class="fas fa-bookmark"></i> 
                The vulnerability of DNN models can cause severe threats to safety-critical applications
                such as video survillence, computer vision task of on ground or under water scenario
                [<a href="https://venturebeat.com/2021/05/29/adversarial-attacks-in-machine-learning-what-they-are-and-how-to-stop-them/">Here</a>].
            </td>
        </tr>

        <tr>
            <td style="text-align: center; vertical-align: middle;">
                <a href="https://www.theverge.com/2021/3/5/22314980/tom-cruise-deepfake-tiktok-videos-ai-impersonator-chris-ume-miles-fisher">
                    <img src="./data/df.jpg" border="0" width="50%">                                
                </a>
                <p><small>An example: Tom Cruise impersonator (left) and the deepfake Tom Cruise (right)</small></p>
            </td>

            <td style="text-align: center; vertical-align: middle;">
                <img src="./data/vulnerability.jpg" border="0" width="80%">
                <p><small>An example: Correct predictions (top) and false predictions (bottom) of underwater and car detection due to the vulnerability of DNN models</small></p>
            </td>
        </tr>
    </tbody>
</table>


</div></div>

<!--==========================================
                    Research goals
===========================================-->
<div class="row container"><div class="row"><br>
 <div class="title">Research Goals</div><hr>
<!-- <h2>Research Goals<a name="Experience"></a></h2> -->
<ul>
    <li>
		<i class="fas fa-bookmark"></i> Developing passive and active defence methods to mitigate the negative impact of falsified multimedia.
		
	</li>
	<li>
		<i class="fas fa-bookmark"></i> Exploring the vulnerability of DNN models, e.g., adversarial and backdoor weakness, and develop methods to boost the rostness of exising architectures. 		
	</li>
	
</ul>
</div></div>

<!--==========================================
                   News
===========================================-->
<div class="row container"><div class="row"><br>
    <div class="title">News</div><hr>
<!-- <h2>News</h2> -->
<ul>
    <li><i class="fa fa-flag" aria-hidden="true"></i> 2021.08: One paper on scene parsing is accepted by TNNLS 2021. &nbsp; <span style="color:red">New!</span></li>
    <li><i class="fa fa-flag" aria-hidden="true"></i> 2021.07: One paper on backdoor attack is accepted by ICCV 2021. &nbsp; <span style="color:red">New!</span></li>
    <li><i class="fa fa-flag" aria-hidden="true"></i> 2021.06: We are releasing DeepFake Game Competition (DFGC) dataset [<a href="https://github.com/yuezunli/celeb-deepfakeforensics">Here</a>]</li>
    <li><i class="fa fa-flag" aria-hidden="true"></i> 2021.05: We are holding DeepFake Game Competition (DFGC) [<a href="http://dfgc2021.iapr-tc4.org/">Here</a>]</li>
    <li><i class="fa fa-flag" aria-hidden="true"></i> 2021.03: One paper on DeepFake-o-meter is accepted by SADFE in conjunction with the IEEE S&P 2021</li>
    <li><i class="fa fa-flag" aria-hidden="true"></i> 2021.02: One paper is accepted by ICASSP 2021.</li>   
</ul>
>> <a href="">More</a>
</div></div>
<!--==========================================
                   Team members
===========================================-->
<div class="row container"><div class="row"><br>
    <div class="title">Team</div><hr>

    <div class="gallery">
    <a target="_blank" href="http://ai-ouc.cn/faculty/dongjy.html">
    <img src="data/dongjy.jpg" alt="" width="100" height="100">
    </a>
    <div class="desc">Junyu Dong </br> Professor, Director</div>
    </div>

    <div class="gallery">
    <a target="_blank" href="https://yuezunli.github.io/">
    <img src="../data/yz.png" alt="" width="100" height="100">
    </a>
    <div class="desc">Yuezun Li </br>  AP, Co-Director</div>
    </div>

    <div class="gallery">
    <a target="_blank" href="https://jiaranzhou.github.io/">
    <img src="https://jiaranzhou.github.io/images/jz2.jpeg" alt="" width="100" height="100">
    </a>
    <div class="desc">Jiaran Zhou </br>  AP</div>
    </div>

    <div class="gallery">
    <a target="_blank" href="">
    <img src="data/qingxuan.jpg" alt="" width="100" height="100">
    </a>
    <div class="desc">Qingxuan Lyu</br> PhD Student</div>
    </div>

    <div class="gallery">
    <a target="_blank" href="">
    <img src="data/qianmin.png" alt="" width="100" height="100">
    </a>
    <div class="desc">Qianmin Chen </br> MSc Student</div>
    </div>
</div>

</div></div>

<!--==========================================
                    Publications
===========================================-->
<!-- <h2>Publications</a></h2> -->
<div class="row container" id="publications"><a name="Publications"></a><div class="row">
    <div class="title">Publications</div><hr>

<ol>

    <li>
        <a href="">Robust Scene Parsing by Mining Supportive Knowledge from Dataset</a><br>
        Ao Luo, Fan Yang, Xin Li, <u>Yuezun Li</u>, Zhicheng Jiao, Hong Cheng, and Siwei Lyu.
        IEEE Transactions on Neural Networks and Learning Systems (TNNLS), 2021. 
    </li>

    <li>
        <a href="">Invisible Backdoor Attack with Sample-Specific Triggers</a><br>
        <u>Yuezun Li</u>, Yiming Li, Baoyuan Wu, Longkang Li, Ran He and Siwei Lyu.
        IEEE International Conference on Computer Vision (ICCV), 2021. 
    </li>

    <li>
        <a href="">DFGC 2021: A DeepFake Game Competition</a><br>
        Bo Peng, Hongxing Fan, Wei Wang, Jing Dong, <u>Yuezun Li</u>, Siwei Lyu, etc.
        International Joint Conference on Biometrics (IJCB), 2021. 
    </li>
    <li>
        <a href="">DeepFake-o-meter: An Open Platform for DeepFake Detection</a><br>
        <u>Yuezun Li</u>,Cong Zhang, Pu Sun, Lipeng Ke, Yan Ju, Honggang Qi and Siwei Lyu.
        Systematic Approaches to Digital Forensic Engineering, in conjunction with the IEEE Security and Privacy Smposium, 2021. 
    </li>
    
<li>
    <a href="https://arxiv.org/pdf/2009.11924.pdf">Exposing GAN-generated Faces Using Inconsistent Corneal Specular Highlights</a><br>
    Shu Hu, <u>Yuezun Li</u> and Siwei Lyu.
    IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), 2021. 
    [<a href="javascript:toggleBibtex('yang2019headpose')">Bibtex</a>]
    <div id="bib_yang2019headpose" class="bibtex noshow">
    <pre>@inproceedings{hu2021corneal,
        author={Hu, Shu and Li, Yuezun and Lyu, Siwei},
        title={Exposing GAN-generated Faces Using Inconsistent Corneal Specular Highlights},
        booktitle={IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)},
        year={2021}}
    </pre>
    </div> 	
    [<a href="https://cse.buffalo.edu/ubmdfl/projects/GAN_detect_iris/GAN_Iris.html">Project page</a>]	 
</li>


<li>
    <a href="">Landmark Breaker: Obstructing DeepFake By Disturbing Landmark Extraction</a><br>
    Pu Sun<sup>*</sup>, <u>Yuezun Li</u><sup>*</sup>, Honggang Qi and Siwei Lyu.
    IEEE International Workshop on Information Forensics and Security (WIFS), 2020. 
    [<a href="javascript:toggleBibtex('sun2020landmarkbreaker')">Bibtex</a>]
    <div id="bib_sun2020landmarkbreaker" class="bibtex noshow">
    <pre>@inproceedings{sun2020landmarkbreaker,
            author = {Pu Sun and Yuezun Li and Honggang Qi and Siwei Lyu},
            title = {Landmark Breaker: Obstructing DeepFake By Disturbing Landmark Extraction},
            booktitle= {IEEE International Workshop on Information Forensics and Security (WIFS)},
            year = {2020}}
    </pre>
    </div>
</li>

<li>
    <a href="">Fast Portrait Segmentation with Highly Light-weight Network</a><br>
    <u>Yuezun Li</u><sup>*</sup>, Ao Luo<sup>*</sup> and Siwei Lyu.
    IEEE International Conference on Image Processing (ICIP), 2020. 
    [<a href="javascript:toggleBibtex('li2020fastseg')">Bibtex</a>]
    <div id="bib_li2020fastseg" class="bibtex noshow">
    <pre>@inproceedings{li2020fastseg,
            author = {Yuezun Li and Ao Luo and Siwei Lyu},
            title = {Fast Portrait Segmentation with Highly Light-weight Network},
            booktitle= {IEEE International Conference on Image Processing (ICIP)},
            year = {2020}}
    </pre>
    </div>
</li>
<li>
    <a href="https://arxiv.org/pdf/1909.12962.pdf">Celeb-DF: A Large-scale Challenging Dataset for DeepFake Forensics</a><br>
    <u>Yuezun Li</u>, Xin Yang, Pu Sun, Honggang Qi and Siwei Lyu.
    IEEE International Conference on Computer Vision and Pattern Recognition (CVPR), 2020. 
    [<a href="javascript:toggleBibtex('Celeb_DF_cvpr20')">Bibtex</a>]
    <div id="bib_Celeb_DF_cvpr20" class="bibtex noshow">
    <pre>@inproceedings{Celeb_DF_cvpr20,
            author = {Yuezun Li and Xin Yang and Pu Sun and Honggang Qi and Siwei Lyu},
            title = {Celeb-DF: A Large-scale Challenging Dataset for DeepFake Forensics},
            booktitle= {IEEE Conference on Computer Vision and Patten Recognition (CVPR)},
            year = {2020}}
    </pre>
    </div>
    [<a href="https://forms.gle/QpoPFy6T9vHmPUQdA">Celeb-DF dataset</a>]
</li>
<li>
    <a href="">Exploring the Vulnerability of Single Shot Module in Object Detectors via Imperceptible Background Patches</a><br>
    <u>Yuezun Li</u>, Xiao Bian, Ming-Ching Chang and Siwei Lyu.
    The British Machine Vision Conference (BMVC), 2019.
    [<a href="javascript:toggleBibtex('li2019ibp')">Bibtex</a>]
    <div id="bib_li2019ibp" class="bibtex noshow">
    <pre>@inproceedings{li2019ibp,
        author={Li, Yuezun and Bian, Xiao and Chang, Mingching and Lyu, Siwei},
        title={Exploring the Vulnerability of Single Shot Module in Object Detectors via Imperceptible Background Patches},
        booktitle={The British Machine Vision Conference (BMVC)},
        year={2019}}
    </pre>
    </div>
</li>

<li>
    <a href="http://openaccess.thecvf.com/content_CVPRW_2019/papers/Media%20Forensics/Li_Exposing_DeepFake_Videos_By_Detecting_Face_Warping_Artifacts_CVPRW_2019_paper.pdf">Exposing DeepFake Videos By Detecting Face Warping Artifacts</a><br>
    <u>Yuezun Li</u> and Siwei Lyu.
    IEEE International Conference on Computer Vision and Pattern Recognition Workshop (CVPRW), 2019. 	
    [<a href="javascript:toggleBibtex('li2019fwa')">Bibtex</a>]
    <div id="bib_li2019fwa" class="bibtex noshow">
    <pre>@inproceedings{li2019fwa,
        author={Li, Yuezun and Lyu, Siwei},
        title={Exposing DeepFake Videos By Detecting Face Warping Artifacts},
        booktitle={IEEE International Conference on Computer Vision and Pattern Recognition Workshop (CVPRW)},
        year={2019}}
    </pre>
    </div>
    [<a href="https://github.com/danmohaha/CVPRW2019_Face_Artifacts">Code</a>]
</li>	
	
</li>
<li>
    <a href="https://arxiv.org/pdf/1811.00661.pdf">Exposing Deep Fakes Using Inconsistent Head Poses</a><br>
    Xin Yang<sup>*</sup>, <u>Yuezun Li</u><sup>*</sup> and Siwei Lyu.
    IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), 2019. 
    [<a href="javascript:toggleBibtex('yang2019headpose')">Bibtex</a>]
    <div id="bib_yang2019headpose" class="bibtex noshow">
    <pre>@inproceedings{yang2019headpose,
        author={Yang, Xin and Li, Yuezun and Lyu, Siwei},
        title={Exposing GAN-synthesized Faces Using Landmark Locations},
        booktitle={IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)},
        year={2019}}
    </pre>
    </div> 	
    [<a href="https://bitbucket.org/ericyang3721/headpose_forensic/src/master/">Code</a>]		
</li>
<li>
    <a href="">Robust Adversarial Perturbation on Deep Proposal-based Models</a><br>
    <u>Yuezun Li</u>, Daniel Tian, Ming-Ching Chang, Xiao Bian and Siwei Lyu.
    The British Machine Vision Conference (BMVC), 2018. 
    [<a href="javascript:toggleBibtex('li2018rap')">Bibtex</a>]
    <div id="bib_li2018rap" class="bibtex noshow">
    <pre>@inproceedings{li2018rap,
            author={Li, Yuezun and Tian, Daniel and Chang, Mingching and Bian, Xiao and Lyu, Siwei},
            title={Robust Adversarial Perturbation on Deep Proposal-based Models},
            booktitle={BMVC},
            year={2018}}
    </pre>
    </div> 	
    [<a href="https://github.com/danmohaha/BMVC2018R-AP">Code</a>]
</li>
<li>
    <a href="https://arxiv.org/pdf/1806.02877.pdf">In Ictu Oculi: Exposing AI Generated Fake Face Videos by Detecting Eye Blinking</a><br>
    <u>Yuezun Li</u>, Ming-Ching Chang and Siwei Lyu.
    IEEE International Workshop on Information Forensics and Security (WIFS), 2018. 
    [<a href="javascript:toggleBibtex('li2018ictu')">Bibtex</a>]
    <div id="bib_li2018ictu" class="bibtex noshow">
    <pre>@inproceedings{li2018ictu,
            title={In Ictu Oculi: Exposing AI Generated Fake Face Videos by Detecting Eye Blinking},
            author={Li, Yuezun and Chang, Ming-Ching and Lyu, Siwei},
            Booktitle={IEEE International Workshop on Information Forensics and Security (WIFS)},
            year={2018}}
    </pre>
    </div> 
    [<a href="https://github.com/danmohaha/WIFS2018_In_Ictu_Oculi">Code</a>][<a href="https://forms.gle/fx6m5PXug99MqJRL9">UADFV dataset</a>]
    

</li>
</ol>
>> <a href="">More</a>
</div></div>


<div id="footer">
	<div id="footer-text">&copy; AI Security Group (AISec) @ OUC 2021 </div>
</div>

</div>

</body></html>
