<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<!-- borrow from https://jonbarron.info/ -->
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'UA-7580334-2');
    </script>

    <title>Yuezun Li's Homepage</title>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">
    
    <meta name="author" content="Yuezun Li">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="stylesheet" type="text/css" href="css/style.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="icon" type="image/jpg" href="images/ouc_icon.jpg">

    <style>
        .collapsible {
            background-color: #ffffff;
            color: #1772d0;
            cursor: pointer;
            padding: 5px;
            border: none;
            text-align: left;
            outline: none;
            font-size: 14px;
            width: 100%;
        }

        .content {
            padding: 10px;
            display: none;
            overflow: hidden;
            background-color: #f1f1f1;
            border: 1px solid #ccc;
        }
    </style>
</head>

<!-- <body onload="startPetCursor();"> -->
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:25%;max-width:40%">
                <a href="images/selfie2024.jpg"><img style="width:100%;max-width:100%;border-radius:50%" alt="profile photo" src="images/selfie2024.jpg" class="hoverZoomLink"></a>
            </td>
            <td style="padding:2.5%;width:70%;vertical-align:middle">
                <p style="text-align:center">
                    <name>Yuezun Li (李岳尊)</name>
                </p>
                <p style="text-align:justify">
                    I am an Assistant Professor/Lecturer at the <a href="https://ai-ouc.cn/">Institute of Artificial Intelligence</a>, at <a href="https://www.ouc.edu.cn/main.htm">Ocean University of China</a>. 
                    My research focuses on multimedia forensics, computer vision and vision security.
                    I have published more than 30 papers in prestigious conferences and journals, including NeurIPS, ICCV, CVPR, ECCV, TIFS, TCSVT, and PR, with <b>over 6,900 citations on Google Scholar <img src="https://img.shields.io/endpoint?url=https%3A%2F%2Fcdn.jsdelivr.net%2Fgh%2Fyuezunli%2Facad-homepage.github.io%40google-scholar-stats%2Fgs_data_shieldsio.json&amp;logo=Google%20Scholar&amp;labelColor=f6f6f6&amp;color=9cf&amp;style=flat&amp;label=citations" />, including several papers with more than 1,000 citations each</b> (CVPR20, CVPRW19, ICASSP19, WIFS18). The WIFS18 paper was also featured on <b>CCTV13’s "World Weekly" special on deepfakes [7:43]</b>. I serve as a reviewer for top conferences and journals, such as TPAMI, TIP, IJCV, TIFS, ICCV, CVPR, AAAI, NeurIPS, ICLR, etc. I have been recognized on Stanford’s 2024 list of the top 2% of scientists worldwide and am a recipient of the 2024 ACM Qingdao Rising Star Award.
                    <!-- <img src="https://img.shields.io/badge/Google Scholar-6400-blue?style=social&logo=google-scholar" style="vertical-align: middle;" /> -->
                </p>
                    
                <p style="text-align:justify">
                    I was a Senior Research Scientist at the Department of Computer Science and Engineering of <a href="https://www.buffalo.edu/">University at Buffalo, SUNY</a>, 
                    working with <a href="https://cse.buffalo.edu/~siweilyu/lyu_lab.html">Siwei Lyu</a>. 
                    I was a summer intern at <a href="https://www.ge.com/research/">GE glocal research center</a> during 2016 - 2018.
                    I received Ph.D. degree in computer science at <a href="https://www.albany.edu/">University at Albany, SUNY</a> in 2020, advised by <a href="https://cse.buffalo.edu/~siweilyu/lyu_lab.html">Siwei Lyu</a> (IEEE/IAPR Fellow). 
                    I received M.S. degree in Computer Science in 2015 and B.S. degree in Software Engineering in 2012 at Shandong University. 
                    
                </p>    
                
                <!-- <button class="collapsible">>> 中文简介 </button>
                <div class="content">
                    <p style="text-align:justify">
                        本硕毕业于山东大学，博士毕业于美国纽约州立大学奥尔巴尼分校。曾任纽约州立大学布法罗分校高级研究科学家。研究方向主要包括多媒体取证、计算机视觉和视觉安全，研究成果发表于NeurIPS, ICCV, CVPR, ECCV, TIFS, TCSVT, PR等国际顶级会议和期刊，<b>谷歌学术引用6400余次，多篇论文的单篇学术引用超过1000次</b>（CVPR20, CVPRW19, ICASSP19, WIFS18）, 其中WIFS18曾被<b>CCTV13《世界周刊深度伪造专题》报道 [7:43]</b>。此外，从事水下视觉信息处理相关研究，致力于海洋浮游植物智能观测技术及相应理论研究。担任TPAMI, TIP, IJCV, TIFS, ICCV, CVPR, AAAI, NeurIPS, ICLR等多个国际顶级期刊和会议的审稿人。主持国家自然科学青年基金、山东省自然科学青年基金、博士后面上项目和站前特别资助项目、中央高校基本科研业务费、青岛市博士后项目等多个项目。入选2024年全球前2%顶尖科学家榜单，获得2024年ACM青岛新星奖。
                    </p>
                </div> -->
                <!-- <br> -->
                
                <p style="text-align:center">
                    </br>
                    <a href="mailto:liyuezun@ouc.edu.cn"><i class="fa fa-envelope" style='font-size:30px'></i>&nbsp; &nbsp; &nbsp;
                    <a href="https://scholar.google.com/citations?user=v0Qt7BAAAAAJ&hl=en"><i class="ai ai-google-scholar-square ai-3x" style='font-size:28px'></i>&nbsp; &nbsp; &nbsp;
                    <a href="https://github.com/yuezunli"><i class="fa fa-github" style='font-size:30px'></i>&nbsp; &nbsp; &nbsp;
                </p>
            </td>
          </tr>
        </tbody></table>
        
        
        <p style="text-align:justify">📢 &nbsp;<span style="color:rgb(255, 60, 0)" ><b>Research group</b></span>: Currently I am leading <a href="https://yuezunli.github.io/ligroup/">Vision Analysis and Security (VAS) lab</a> <img src="images/logo.png" width="25">. Our lab has multiple openings. <b>Please drop me an email if you are interested in internship / M.S. program.</b>
        I am also a member of <a href="https://yuezunli.github.io/planktongroup/">PVOA group</a> which focuses on underwater computer vision reserach. Drop me an email if you are interested.
        </p>
        
        <p style="text-align:left"><i class="fa fa-bell" aria-hidden="true" style="color:orange"></i>
            <span style="color:orange" ><b>Representative works</b></span>:         
                
            <table class="tab1" width="100%" style="table-layout:fixed;word-break:break-all;background:#fafafa">
                    <tr>
                        <th>CVPR'20</th>
                        <th>CVPRW'19</th>
                        <th>WIFS'18</th>
                        <th>ICASSP'19</th>
                        <th>ICCV'21</th>
                    </tr>
                    <tr>
                        <td><a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Li_Celeb-DF_A_Large-Scale_Challenging_Dataset_for_DeepFake_Forensics_CVPR_2020_paper.pdf">[Celeb-DF]</a>
                             <a href="https://github.com/yuezunli/celeb-deepfakeforensics">[<i class="fa fa-github" style="color:black"></i>]</a></td>
                        <td><a href="http://openaccess.thecvf.com/content_CVPRW_2019/papers/Media%20Forensics/Li_Exposing_DeepFake_Videos_By_Detecting_Face_Warping_Artifacts_CVPRW_2019_paper.pdf">[FWA]</a>
                            <a href="https://github.com/yuezunli/CVPRW2019_Face_Artifacts">[<i class="fa fa-github" style="color:black"></i>]</a></td>
                        <td><a href="https://arxiv.org/abs/1806.02877">[In Ictu Oculi]</a>
                            <a href="https://github.com/yuezunli/WIFS2018_In_Ictu_Oculi">[<i class="fa fa-github" style="color:black"></i>]</a></td>
                        <td><a href="https://arxiv.org/pdf/1811.00661">[Head Pose]</a>
                            <a href="https://github.com/rbassett3/headpose_forensic">[<i class="fa fa-github" style="color:black"></i>]</a></td>
                        <td><a href="http://openaccess.thecvf.com/content/ICCV2021/html/Li_Invisible_Backdoor_Attack_With_Sample-Specific_Triggers_ICCV_2021_paper.html">[ISSBA]</a>
                            <a href="https://github.com/yuezunli/ISSBA">[<i class="fa fa-github" style="color:black"></i>]</a></td>
                    </tr>
                    <tr>
                        <td>
                            <img src="https://img.shields.io/badge/citations-1400+-blue?style=social&logo=google-scholar" />
                        </td>
                        <td>
                            <img src="https://img.shields.io/badge/citations-1100+-blue?style=social&logo=google-scholar" />
                        </td>
                        <td>
                            <img src="https://img.shields.io/badge/citations-1100+-blue?style=social&logo=google-scholar" />
                        </td>
                        <td>
                            <img src="https://img.shields.io/badge/citations-1100+-blue?style=social&logo=google-scholar" />
                        </td>
                        <td>
                            <img src="https://img.shields.io/badge/citations-500+-blue?style=social&logo=google-scholar" />
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <iframe width="100" height="80"
                                src="https://www.youtube.com/embed/vLTiluewGQY">
                            </iframe>                            
                        </td>
                        <td>
                            <img width="150" height="70" src="images/representative/fwa.png">
                        </td>
                        <td>
                            <a href="https://tv.cctv.com/2019/04/28/VIDE0aLKiWV83f2PrbZDF4G0190428.shtml"><img width="120" height="70" src="images/representative/wifs18.png"></a>
                        </td>
                        <td>
                            <img width="100" height="90" src="images/representative/headpose.png">
                        </td>
                        <td>
                            <iframe width="100" height="80"
                                src="https://www.youtube.com/embed/yFW5lQL9JK8">
                            </iframe>                            
                        </td>
                    </tr>
                </table>       
        
            </p>


        
        <!-- <hr> -->
        <div style="padding:10px;width:100%;vertical-align:middle;background-color:#eeefff;">
            <a href="#News">[News]</a> &nbsp &nbsp &nbsp &nbsp
            <a href="#Publications">[Publications]</a> &nbsp &nbsp &nbsp &nbsp
            <a href="#Fundings">[Fundings]</a> &nbsp &nbsp &nbsp &nbsp
            <a href="#Service">[Service]</a> &nbsp &nbsp &nbsp &nbsp
            <a href="http://it.ouc.edu.cn/lyz2/main.htm">[中文版]</a> &nbsp &nbsp &nbsp &nbsp
            <!-- <a href="https://yuezunli.github.io/ligroup/"><b>[视觉分析与安全课题组]</b></a> -->
        </div>
        
        <!--==========================================
                   news
        ===========================================-->
        <a name="News"></a>
        <heading style="padding:10px">🎉 News</heading>    
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
            <td style="padding:10px;width:100%;vertical-align:middle">
            <ul>
                <li><b>[2025.1]</b>: <b>The work of TSOM (WACV 2025) is elected as Oral. &nbsp; <span style="color:red">New!</span></b></li>
                <li><b>[2025.1]</b>: <b>I gave a talk on face forensics in the wild at CSIG Young Scholars forum. &nbsp; <span style="color:red">New!</span></b></li>
                <li><b>[2024.11]</b>: <b>One paper on phytoplankton tracking is accepted by IEEE TCSVT. &nbsp; <span style="color:red">New!</span></b></li>
                <li><b>[2024.11]</b>: <b>Awarded BMVC outstanding reviewer. &nbsp; <span style="color:red">New!</span></b></li>
                <li><b>[2024.10]</b>: <b>One paper on sequential deepfake detection is accepted by WACV. &nbsp; <span style="color:red">New!</span></b></li>
                <li><b>[2024.09]</b>: <b>One paper on deepfake detection is accepted by NeurIPS. &nbsp; <span style="color:red">New!</span></b></li>
                <li><b>[2024.09]</b>: <b>Elected among <a href="https://topresearcherslist.com/Home/Search?AuthFull=Li,+Yuezun">World's Top 2% Scientists 2024 by Stanford University</a>. &nbsp; <span style="color:red">New!</span></b></li>
                <li><b>[2024.09]</b>: <b>One paper on quality-agnostic deepfake detection is accepted by ACCV. &nbsp; <span style="color:red">New!</span></b></li>
                <li><b>[2024.08]</b>: <b>One paper on 3D adversarial meshes are accepted by PG. &nbsp; <span style="color:red">New!</span></b></li>
                <li><b>[2024.07]</b>: <b>Two papers on image manipulation detection are accepted by BMVC. &nbsp; <span style="color:red">New!</span></b></li>
                <li><b>[2024.07]</b>: <b>One paper on transferable deepfake detection is accepted by IEEE TIFS. &nbsp; <span style="color:red">New!</span></b></li>
                <li><b>[2024.07]</b>: <b>One paper on generalizable deepfake detection is accepted by ECCV. &nbsp; <span style="color:red">New!</span></b></li>
                <li><b>[2024.05]</b>: <b>One paper on multi-face deepfake detection is accepted by IEEE TCSVT. &nbsp; <span style="color:red">New!</span></b></li>
                <li><b>[2024.04]</b>: <b>One paper on deepfake detection is accepted by IEEE TIFS. &nbsp; <span style="color:red">New!</span></b></li>
                <li><b>[2024.04]</b>: One paper on deepfake defense is accepted by IEEE TETC. </li>                
            </ul>
            >> <a href="more_news.html">More</a>
          </td>
        </tr>
        </tbody></table>
        <hr>               
        
        <!--==========================================
                   publications
        ===========================================-->
        <a name="Publications"></a>
        <heading style="padding:10px;">📝 Publications</heading><font size="1">(+ Advised student, <i class="fa fa-envelope-o" aria-hidden="true"></i> Corresponding author, * Equal contribution)</font>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;padding-top:10px;"><tbody> 
        <tr>
            <tr><td style="padding:10px;"><i class="fa fa-calendar" aria-hidden="true"></i>&nbsp;<b>Preprints</b></td></tr>
            <tr>
                <td style="padding:10px;width:30%;vertical-align:middle;text-align:center;">
                    <img src='images/forensicsadapter2024arxiv.png' width="170"></div>
                </td>
                <td valign="middle">
                    <p>
                    <a href="https://arxiv.org/pdf/2411.19715">
                        <papertitle>Forensics Adapter: Adapting CLIP for Generalizable Face Forgery Detection</papertitle>
                    </a>
                    <br>
                    Xinjie Cui<sup>+</sup>, <b>Yuezun Li<sup> <i class="fa fa-envelope-o" aria-hidden="true"></i></sup></b>, Ao Luo, Jiaran Zhou, Junyu Dong
                    <br>
                    arXiv:2411.19715, 2024.
                </td>
            </tr>
            
            <tr>
                <td style="padding:10px;width:30%;vertical-align:middle;text-align:center;">
                    <img src='images/faceposion2024arxiv.png' width="170"></div>
                </td>
                <td valign="middle">
                    <p>
                    <a href="https://arxiv.org/pdf/2412.01101">
                        <papertitle>Hiding Faces in Plain Sight: Defending DeepFakes by Disrupting Face Detection</papertitle>
                    </a>
                    <br>
                    Delong Zhu<sup>+</sup>, <b>Yuezun Li</b><sup> <i class="fa fa-envelope-o" aria-hidden="true"></i></sup>, Baoyuan Wu, Jiaran Zhou, Zhibo Wang, Siwei Lyu
                    <br>
                    arXiv:2412.01101, 2024. (Extended from ICME 2023)
                </td>
            </tr>

            <tr>
                <td style="padding:10px;width:30%;vertical-align:middle;text-align:center;">
                    <img src='images/hrgr2024arxiv.png' width="170"></div>
                </td>
                <td valign="middle">
                    <p>
                    <a href="https://arxiv.org/abs/2410.21861">
                        <papertitle>HRGR: Enhancing Image Manipulation Detection via Hierarchical Region-aware Graph Reasoning</papertitle>
                    </a>
                    <br>
                    Xudong Wang<sup>+</sup>, <b>Yuezun Li<sup> <i class="fa fa-envelope-o" aria-hidden="true"></i></sup></b>, Huiyu Zhou, Jiaran Zhou, Junyu Dong
                    <br>
                    arXiv:2410.21861, 2024.
                </td>
            </tr>
            
            <tr>
                <td style="padding:10px;width:30%;vertical-align:middle;text-align:center;">
                    <img src='images/dfcam2024arxiv.png' width="170"></div>
                </td>
                <td valign="middle">
                    <p>
                    <a href="https://arxiv.org/pdf/2409.03200">
                        <papertitle>Active Fake: DeepFake Camouflage</papertitle>
                    </a>
                    <br>
                    Pu Sun, Honggang Qi<sup> <i class="fa fa-envelope-o" aria-hidden="true"></i></sup>, <b>Yuezun Li</b><sup> <i class="fa fa-envelope-o" aria-hidden="true"></i></sup>
                    <br>
                    arXiv:2409.03200, 2024. 
                </td>
            </tr>

            <tr>
                <td style="padding:10px;width:30%;vertical-align:middle;text-align:center;">
                    <img src='images/uwstereo2024arxiv.png' width="170"></div>
                </td>
                <td valign="middle">
                    <p>
                    <a href="https://arxiv.org/abs/2409.01782">
                        <papertitle>UWStereo: A Large Synthetic Dataset for Underwater Stereo Matching</papertitle>
                    </a>
                    <br>
                    Qingxuan Lv<sup>+</sup>, Junyu Dong<sup> <i class="fa fa-envelope-o" aria-hidden="true"></i></sup>, <b>Yuezun Li</b><sup> <i class="fa fa-envelope-o" aria-hidden="true"></i></sup>, Sheng Chen, Hui Yu, Shu Zhang, Wenhan Wang
                    <br>
                    arXiv:2409.01782, 2024. 
                </td>
            </tr>

            <tr>
                <td style="padding:10px;width:30%;vertical-align:middle;text-align:center;">
                    <img src='images/hypersfda2024arxiv.png' width="170"></div>
                </td>
                <td valign="middle">
                    <p>
                    <a href="https://arxiv.org/abs/2405.06916">
                        <papertitle>High-order Neighborhoods Know More: HyperGraph Learning Meets Source-free Unsupervised Domain Adaptation</papertitle>
                    </a>
                    <br>
                    Jinkun Jiang<sup>+</sup>, Qingxuan Lv, <b>Yuezun Li</b><sup> <i class="fa fa-envelope-o" aria-hidden="true"></i></sup>, Yong Du, Sheng Chen, Hui Yu, Junyu Dong<sup> <i class="fa fa-envelope-o" aria-hidden="true"></i></sup>
                    <br>
                    arXiv:2405.06916, 2024. 
                </td>
            </tr>
            
        </tr>
        

        <tr>
            <tr>
                <td style="padding:10px;" colspan="2"><i class="fa fa-calendar" aria-hidden="true"></i>&nbsp;<b>2025
                    &nbsp; (WACV*1)
                </b></td>
            </tr>
            <tr>                
                <td style="padding:10px;width:30%;vertical-align:middle;text-align:center;">
                    <img src='images/tsom2024wacv.png' width="170"></div>
                        </td>
                <td valign="middle">
                    <p>
                    <a href="">
                        <papertitle>Texture, Shape and Order Matter: A New Transformer Design for Sequential DeepFake Detection</papertitle>
                    </a>
                    <br>
                    Yunfei Li<sup>+</sup>, <b>Yuezun Li</b><sup> <i class="fa fa-envelope-o" aria-hidden="true"></i></sup>, Xin Wang, Baoyuan Wu, Jiaran Zhou, Junyu Dong.
                    <br>
                    IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2025. <b><span style="color:red">(Oral)</span></b>
                </td>
            </tr>
        </tr>

        <tr>
            <tr>
                <td style="padding:10px;" colspan="2"><i class="fa fa-calendar" aria-hidden="true"></i>&nbsp;<b>2024
                &nbsp; (NeurIPS*1, TIFS*2, TCSVT*2, BMVC*2, ACCV*1, PG*1, CVIU*2, TETC*1, ICASSP*1, ICMR*1, KBS*1)</b></td>
            </tr>
            <tr>
                <td style="padding:10px;width:30%;vertical-align:middle;text-align:center;">
                    <img src='images/pytracker2024arxiv.png' width="170"></div>
                </td>
                <td valign="middle">
                    <p>
                    <a href="https://arxiv.org/abs/2407.00352">
                        <papertitle>PhyTracker: An Online Tracker for Phytoplankton</papertitle>
                    </a>
                    <br>
                    Yang Yu<sup>+</sup>, Qingxuan Lv, <b>Yuezun Li</b><sup> <i class="fa fa-envelope-o" aria-hidden="true"></i></sup>, Zhiqiang Wei, Junyu Dong<sup> <i class="fa fa-envelope-o" aria-hidden="true"></i></sup>
                    <br>
                    IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 2024. 
                </td>
            </tr>
            
            <tr>                
                <td style="padding:10px;width:30%;vertical-align:middle;text-align:center;">
                    <img src='images/freqblender2024neurips.png' width="170"></div>
                        </td>
                <td valign="middle">
                    <p>
                    <a href="https://arxiv.org/abs/2404.13872">
                        <papertitle>FreqBlender: Enhancing DeepFake Detection by Blending Frequency Knowledge</papertitle>
                    </a>
                    <br>
                    Hanzhe Li<sup>+</sup>, Jiaran Zhou, <b>Yuezun Li</b><sup> <i class="fa fa-envelope-o" aria-hidden="true"></i></sup>, Baoyuan Wu, Bin Li, Junyu Dong.
                    <br>
                    The Annual Conference on Neural Information Processing Systems (NeurIPS), 2024. 
                </td>
            </tr>
            <tr>
                <td style="padding:10px;width:30%;vertical-align:middle;text-align:center;">
                    <img src='images/dpl2024accv.png' width="170"></div>
                        </td>
                <td valign="middle">
                    <p>
                    <a href="https://arxiv.org/pdf/2410.07633">
                        <papertitle>DPL: Cross-quality DeepFake Detection via Dual Progressive Learning</papertitle>
                    </a>
                    <br>
                    Dongliang Zhang<sup>+</sup>, Yunfei Li<sup>+</sup>, Jiaran Zhou, <b>Yuezun Li</b><sup> <i class="fa fa-envelope-o" aria-hidden="true"></i></sup>.
                    <br>
                    Asian Conference on Computer Vision (ACCV), 2024. 
                </td>
            </tr>
            <tr>
                <td style="padding:10px;width:30%;vertical-align:middle;text-align:center;">
                    <img src='images/tpam2024pg.png' width="170"></div>
                        </td>
                <td valign="middle">
                    <p>
                    <a href="">
                        <papertitle>TPAM: Transferable Perceptual-constrained Adversarial Meshes</papertitle>
                    </a>
                    <br>
                    Tengjia Kang<sup>+</sup>, <b>Yuezun Li</b>, Jiaran Zhou, Shiqing Xin, Junyu Dong, Changhe Tu.
                    <br>
                    Pacific Graphics (PG), 2024. 
                </td>
            </tr>

            <tr>
                <td style="padding:10px;width:30%;vertical-align:middle;text-align:center;">
                    <img src='images/fastforensics2024bmvc.png' width="170"></div>
                        </td>
                <td valign="middle">
                    <p>
                    <a href="https://arxiv.org/pdf/2408.16582">
                        <papertitle>FastForensics: Efficient Two-Stream Design for Real-Time Image Manipulation Detection</papertitle>
                    </a>
                    <br>
                    Yangxiang Zhang<sup>+</sup>, <b>Yuezun Li</b><sup> <i class="fa fa-envelope-o" aria-hidden="true"></i></sup>, Ao Luo, Jiaran Zhou, Junyu Dong.
                    <br>
                    British Machine Vision Conference (BMVC), 2024. 
                </td>
            </tr>

            <tr>
                <td style="padding:10px;width:30%;vertical-align:middle;text-align:center;">
                    <img src='images/mumpy2024arxiv.png' width="170"></div>
                        </td>
                <td valign="middle">
                    <p>
                    <a href="https://arxiv.org/pdf/2404.11054">
                        <papertitle>Mumpy: Multilateral Temporal-view Pyramid Transformer for Video Inpainting Detection</papertitle>
                    </a>
                    <br>
                    Ying Zhang<sup>+</sup>, <b>Yuezun Li</b><sup> <i class="fa fa-envelope-o" aria-hidden="true"></i></sup>, Bo Peng, Jiaran Zhou, Huiyu Zhou, Junyu Dong.
                    <br>
                    British Machine Vision Conference (BMVC), 2024. 
                </td>
            </tr>

            <tr>
                <td style="padding:10px;width:30%;vertical-align:middle;text-align:center;">
                    <img src='images/domainforensics2024tifs.png' width="170"></div>
                        </td>
                <td valign="middle">
                    <p>
                    <a href="https://arxiv.org/abs/2312.10680">
                        <papertitle>DomainForensics: Exposing Face Forgery across Domains via Bi-directional Adaptation</papertitle>
                    </a>
                    <br>
                    Qingxuan Lv<sup>+</sup>, <b>Yuezun Li</b><sup> <i class="fa fa-envelope-o" aria-hidden="true"></i></sup>, Junyu Dong<sup> <i class="fa fa-envelope-o" aria-hidden="true"></i></sup>, Sheng Chen, Hui Yu, Huiyu Zhou, Shu Zhang.
                    <br>
                    IEEE Transactions on Information Forensics and Security (TIFS), 2024.  
                </td>
            </tr>

            <tr>
                <td style="padding:10px;width:30%;vertical-align:middle;text-align:center;">
                    <img src='images/ssbi2024eccv.png' width="170"></div>
                        </td>
                <td valign="middle">
                    <p>
                    <a href="">
                        <papertitle>Fake It till You Make It: Curricular Dynamic Forgery Augmentations towards General Deepfake Detection</papertitle>
                    </a>
                    <br>
                    Yuzhen Lin, Wentang Song, Bin Li, <b>Yuezun Li</b>, Jiangqun Ni, Han Chen, Qiushi Li.
                    <br>
                    European Conference on Computer Vision (ECCV), 2024.  
                </td>
            </tr>

            <tr>
                <td style="padding:10px;width:30%;vertical-align:middle;text-align:center;">
                    <img src='images/multi-face2023arxiv.png' width="170"></div>
                        </td>
                <td valign="middle">
                    <p>
                    <a href="https://arxiv.org/abs/2308.01520">
                        <papertitle>COMICS: End-to-end Bi-grained Contrastive Learning for Multi-face Forgery Detection</papertitle>
                    </a>
                    <br>
                    Cong Zhang<sup>+</sup>, Honggang Qi, Shuhui Wang, <b>Yuezun Li</b><sup> <i class="fa fa-envelope-o" aria-hidden="true"></i></sup>, Siwei Lyu.
                    <br>
                    IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 2024.
                    <br>
                    <a href="https://github.com/zhangconghhh/COMICS">[Code]</a>               
                    <br>
                </td>
            </tr>
            
            <tr>
                <td style="padding:10px;width:30%;vertical-align:middle;text-align:center;">
                    <img src='images/forest2023icme.png' width="170"></div>
                        </td>
                <td valign="middle">
                    <p>
                    <a href="https://arxiv.org/abs/2308.00964">
                        <papertitle>ForensicsForest Family: A Series of Multi-scale Hierarchical Cascade Forests for Detecting GAN-generated Faces</papertitle>
                    </a>
                    <br>
                    Jiucui Lu<sup>+</sup>, Jiaran Zhou<sup> <i class="fa fa-envelope-o" aria-hidden="true"></i></sup>, Junyu Dong, Bin Li, Siwei Lyu, <b>Yuezun Li</b><sup> <i class="fa fa-envelope-o" aria-hidden="true"></i></sup>.
                    <br>
                    IEEE Transactions on Information Forensics and Security (TIFS), 2024. (Extended from ICME 2023)
                    <br>
                    <a href="https://github.com/OUC-VAS/ForensicsForest">[Code]</a>               
                    <br>
                </td>
            </tr>
            <tr>
                <td style="padding:10px;width:30%;vertical-align:middle;text-align:center;">
                    <img src='images/fakecatcher2024tetc.png' width="170"></div>
                        </td>
                <td valign="middle">
                    <p>
                    <a href="https://arxiv.org/html/2307.14593v2">
                        <papertitle>FakeTracer: Catching Face-swap DeepFakes via Implanting Traces in Training</papertitle>
                    </a>
                    <br>
                    Pu Sun<sup>+</sup>, Honggang Qi, <b>Yuezun Li</b><sup> <i class="fa fa-envelope-o" aria-hidden="true"></i></sup>, Siwei Lyu.
                    <br>
                    IEEE Transactions on Emerging Topics in Computing (TETC), 2024. (Extended from ICIP2022)
                    <br>
                    <a href="">[Code]</a>               
                    <br>
                </td>
            </tr>

            <tr>
                <td style="padding:10px;width:30%;vertical-align:middle;text-align:center;">
                    <img src='images/vse2024icmr.png' width="170"></div>
                        </td>
                <td valign="middle">
                    <p>
                    <a href="">
                        <papertitle>Dynamic Soft Labeling for Visual Semantic Embedding</papertitle>
                    </a>
                    <br>
                    Jiaao Yu<sup>+</sup>, Yunlai Ding, Junyu Dong, <b>Yuezun Li</b>.
                    <br>
                    ACM International Conference on Multimedia Retrieval (ICMR), 2024. 
                    <br>
                    <a href="">[Code]</a>               
                    <br>
                </td>
            </tr>

            <tr>
                <td style="padding:10px;width:30%;vertical-align:middle;text-align:center;">
                    <img src='images/mvapp2024kbs.png' width="170"></div>
                        </td>
                <td valign="middle">
                    <p>
                    <a href="">
                        <papertitle>Multiview Adaptive Attention Pooling for Image-Text Retrieval</papertitle>
                    </a>
                    <br>
                    Yunlai Ding<sup>+</sup>, Jiaao Yu<sup>+</sup>, Qingxuan Lv, Haoran Zhao, Junyu Dong, <b>Yuezun Li</b>.
                    <br>
                    Knowledge-Based Systems (KBS), 2024. 
                    <br>
                    <a href="">[Code]</a>               
                    <br>
                </td>
            </tr>

            <tr>
                <td style="padding:10px;width:30%;vertical-align:middle;text-align:center;">
                    <img src='images/lmkbreaker2024cviu.png' width="170"></div>
                        </td>
                <td valign="middle">
                    <p>
                    <a href="">
                        <papertitle>LandmarkBreaker: A Proactive Method to Obstruct DeepFakes via Disrupting Facial Landmark Extraction</papertitle>
                    </a>
                    <br>
                    <b>Yuezun Li</b>, Pu Sun, Honggang Qi, Siwei Lyu.
                    <br>
                    Computer Vision and Image Understanding (CVIU), 2024. (Extended from WIFS2020)
                    <br>
                    <a href="">[Code]</a>               
                    <br>
                </td>
            </tr>

            <tr>
                <td style="padding:10px;width:30%;vertical-align:middle;text-align:center;">
                    <img src='images/wdeco2024icassp.png' width="170"></div>
                        </td>
                <td valign="middle">
                    <p>
                    <a href="">
                        <papertitle>Enhancing Adversarial Robustness of DNNs via Weight Decorrelation in Training</papertitle>
                    </a>
                    <br>
                    Cong Zhang, <b>Yuezun Li</b>, Honggang Qi, Siwei Lyu.
                    <br>
                    IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2024.  
                    <br>
                    <a href="">[Code]</a>               
                    <br>
                </td>
            </tr>

            <tr>
                <td style="padding:10px;width:30%;vertical-align:middle;text-align:center;">
                    <img src='images/adani2023cviu.png' width="170"></div>
                        </td>
                <td valign="middle">
                    <p>
                    <a href="">
                        <papertitle>AdaNI: Adaptive Noise Injection to Improve Adversarial Robustness</papertitle>
                    </a>
                    <br>
                    <b>Yuezun Li</b>, Cong Zhang, Honggang Qi, Siwei Lyu.
                    <br>
                    Computer Vision and Image Understanding (CVIU), 2024.  
                    <br>
                    <a href="">[Code]</a>               
                    <br>
                </td>
            </tr>

            <tr><td style="padding:10px;"><i class="fa fa-calendar" aria-hidden="true"></i>&nbsp;<b>2023</b></td></tr>
            
            <tr>
                <td style="padding:10px;width:30%;vertical-align:middle;text-align:center;">
                    <img src='images/pmot2023jmse.png' width="150"></div>
                        </td>
                <td valign="middle">
                    <p>
                    <a href="">
                        <papertitle>PMOT2023: A large-scale multi-object tracking (MOT) dataset with application to phytoplankton observation</papertitle>
                    </a>
                    <br>
                    Jiaao Yu<sup>+</sup>, Qingxuan Lv, <b>Yuezun Li</b><sup> <i class="fa fa-envelope-o" aria-hidden="true"></i></sup>, Junyu Dong<sup> <i class="fa fa-envelope-o" aria-hidden="true"></i></sup>, Haoran Zhao, Qiong Li.
                    <br>
                    Journal of Marine Science and Engineering (JMSE), 2023. (interdiscipline)  
                    <br>
                    <a href="">[Code]</a>               
                    <br>
                </td>
            </tr>
            <tr>
                <td style="padding:10px;width:30%;vertical-align:middle;text-align:center;">
                    <img src='images/sceneparsing2021tnnls.png' width="150"></div>
                        </td>
                <td valign="middle">
                    <p>
                    <a href="">
                        <papertitle>Robust Scene Parsing by Mining Supportive Knowledge from Dataset</papertitle>
                    </a>
                    <br>
                    Ao Luo, Fan Yang, Xin Li, <b>Yuezun Li</b>, Zhicheng Jiao, Hong Cheng, Siwei Lyu.
                    <br>
                    IEEE Transactions on Neural Networks and Learning Systems (TNNLS), 2023.  
                    <br>
                    <a href="">[Code]</a>               
                    <br>
                </td>
            </tr>
            <tr>
                <td style="padding:10px;width:30%;vertical-align:middle;text-align:center;">
                    <img src='images/lafea2023tcsvt.png' width="120"></div>
                        </td>
                <td valign="middle">
                    <p>
                    <a href="">
                        <papertitle>LaFea: Learning Latent Representation beyond Feature for Universal Domain Adaptation</papertitle>
                    </a>
                    <br>
                    Qingxuan Lv<sup>+</sup>, <b>Yuezun Li</b><sup> <i class="fa fa-envelope-o" aria-hidden="true"></i></sup>, Junyu Dong<sup> <i class="fa fa-envelope-o" aria-hidden="true"></i></sup>, Ziqian Guo.
                    <br>
                    IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 2023.  
                    <br>
                    <a href="">[Code]</a>                
                    <br>
                </td>
            </tr>

            <tr>
                <td style="padding:10px;width:30%;vertical-align:middle;text-align:center;">
                    <img src='images/forest2023icme.png' width="200"></div>
                        </td>
                <td valign="middle">
                    <p>
                    <a href="papers/ICME2023_ForensicsForest .pdf">
                        <papertitle>Forensics Forest: Multi-scale Hierarchical Cascade Forest for Detecting GAN-generated Faces</papertitle>
                    </a>
                    <br>
                    Jiucui Lu<sup>+</sup>, <b>Yuezun Li</b><sup> <i class="fa fa-envelope-o" aria-hidden="true"></i></sup>, Jiaran Zhou, Bin Li, Siwei Lyu.
                    <br>
                    IEEE International Conference on Multimedia and Expo (ICME), 2023. <b><span style="color:red">(Oral)</span></b>
                    <br>
                    <a href="">[Code]</a>                
                    <br>
                </td>
            </tr>
    
            <tr>
                <td style="padding:10px;width:30%;vertical-align:middle;text-align:center;">
                    <img src='images/faceposion2023icme.png' width="180"></div>
                        </td>
                <td valign="middle">
                    <p>
                    <a href="papers/ICME2023_FacePoison .pdf">
                        <papertitle>Face Poison: Obstructing DeepFakes by Disrupting Face Detection</papertitle>
                    </a>
                    <br>
                    <b>Yuezun Li</b>, Jiaran Zhou, Siwei Lyu.
                    <br>
                    IEEE International Conference on Multimedia and Expo (ICME), 2023. 
                    <br>
                    <a href="">[Code]</a>                
                    <br>
                </td>
            </tr>

            <td style="padding:10px;width:30%;vertical-align:middle;text-align:center;;text-align:center;">
                <img src='images/fmaa2023cose.png' width="130">
            </td>
            <td valign="middle">
                <p>
                <a href="">
                    <papertitle>Improving Transferable Adversarial Attack via Feature-Momentum</papertitle>
                </a>
                <br>
                Xianglong He<sup>+</sup>, <b>Yuezun Li</b><sup> <i class="fa fa-envelope-o" aria-hidden="true"></i></sup>, Haipeng Qu, Junyu Dong.
                <br>
                Computers & Security (COSE), 2023.  
                <br>
                <a href="https://github.com/XianglongHe/FMAA">[Code]</a>               
                <br>
            </td>
        </tr> 

        <tr>
            <td style="padding:10px;width:30%;vertical-align:middle;text-align:center;">
                <img src='images/big2022pr.png' width="180"></div>
                    </td>
            <td valign="middle">
                <p>
                <a href="">
                    <papertitle>Watching the BiG Artifacts: Exposing DeepFake Videos via Bi-Granularity Artifacts</papertitle>
                </a>
                <br>
                Han Chen<sup>*</sup>, <b>Yuezun Li</b><sup>*</sup>, Dongdong Lin, Bin Li, Junqiang Wu.
                <br>
                Pattern Recognition (PR), 2023.  
                <br>
                <a href="">[Code]</a>               
                <br>
            </td>
        </tr> 
        <tr><td style="padding:10px"><i class="fa fa-calendar" aria-hidden="true"></i>&nbsp;<b>2022</b></td></tr>
        <tr>
            <td style="padding:10px;width:30%;vertical-align:middle;text-align:center;">
                <img src='images/facetracer2022icip.png' width="180"></div>
                    </td>
            <td valign="middle">
                <p>
                <a href="">
                    <papertitle>Faketracer: Exposing DeepFakes with Training Data Contamination</papertitle>
                </a>
                <br>
                Pu Sun, <b>Yuezun Li</b><sup> <i class="fa fa-envelope-o" aria-hidden="true"></i></sup>, Honggang Qi, Siwei Lyu.
                <br>
                IEEE Conference on Image Processing (ICIP), 2022. 
                <br>
                <a href="">[Code]</a>               
                <br>
            </td>
        </tr> 

        <tr>
            <td style="padding:10px;width:30%;vertical-align:middle;text-align:center;">
                <img src='images/landmark2022prl.png' width="180"></div>
                    </td>
            <td valign="middle">
                <p>
                <a href="">
                    <papertitle>LandmarkGAN: Synthesizing Faces from Landmarks</papertitle>
                </a>
                <br>
                Pu Sun<sup>*</sup>, <b>Yuezun Li</b><sup>*</sup>, Honggang Qi, Siwei Lyu.
                <br>
                Pattern Recognition Letters, 2022.  
                <br>
                <a href="">[Code]</a>               
                <br>
            </td>
        </tr> 

        <tr>
            <td style="padding:10px;width:30%;vertical-align:middle;text-align:center;">
                <img src='images/duallevel2022pr.jpg' width="180"></div>
                    </td>
            <td valign="middle">
                <p>
                <a href="">
                    <papertitle>Learning a Deep Dual-level Network for Robust DeepFake Detection</papertitle>
                </a>
                <br>
                Wenbo Pu, Jing Hu, Xin Wang, <b>Yuezun Li</b>, Shu Hu, Bin Zhu, Qi Song, Xi Wu, Siwei Lyu.
                <br>
                Pattern Recognition (PR), 2022.  
                <br>
                <a href="">[Code]</a>               
                <br>
            </td>
        </tr> 

        <tr>
            <td style="padding:10px;width:30%;vertical-align:middle;text-align:center;">
                <img src='images/d-by-s2022mipr.png' width="130"></div>
                    </td>
            <td valign="middle">
                <p>
                <a href="">
                    <papertitle>Detection-by-Simulation: Exposing DeepFake via Simulating Forgery using Face Reconstruction</papertitle>
                </a>
                <br>
                Jiaran Zhou and <b>Yuezun Li</b><sup> <i class="fa fa-envelope-o" aria-hidden="true"></i></sup>.
                <br>
                IEEE International Conference on Multimedia Information Processing, Retrieval (MIPR), 2022. 
                <br>
                <a href="">[Code]</a>               
                <br>
            </td>
        </tr>
        <tr><td style="padding:10px"><i class="fa fa-calendar" aria-hidden="true"></i>&nbsp;<b>2021</b></td></tr>
        <tr >
            <td style="padding:10px;width:30%;vertical-align:middle;text-align:center;">
                <img src='images/ssba2021iccv.png' width="180"></div>
                    </td>
            <td valign="middle">
                <p>
                <a href="">
                    <papertitle>Invisible Backdoor Attack with Sample-Specific Triggers</papertitle>
                </a>
                <br>
                <b>Yuezun Li</b>, Yiming Li, Baoyuan Wu, Longkang Li, Ran He, Siwei Lyu.
                <br>
                IEEE International Conference on Computer Vision (ICCV), 2021. 
                <br>
                <a href="">[Code]</a>               
                <br>
            </td>
        </tr> 

        <tr>
            <td style="padding:10px;width:30%;vertical-align:middle;text-align:center;">
                <img src='images/transrpn2021cviu.jpg' width="150"></div>
                    </td>
            <td valign="middle">
                <p>
                <a href="">
                    <papertitle>TransRPN: Towards the Transferable Adversarial Perturbations Using Region Proposal Networks and Beyond</papertitle>
                </a>
                <br>
                <b>Yuezun Li</b>, Ming-Ching Chang, Pu Sun, Honggang Qi, Junyu Dong, Siwei Lyu.
                <br>
                International Journal on Computer Vision and Image Understanding (CVIU), 2021.  
                <br>
                <a href="">[Code]</a>               
                <br>
            </td>
        </tr> 

        <tr>
            <td style="padding:10px;width:30%;vertical-align:middle;text-align:center;">
                <img src='images/dfdc2021.png' width="150"></div>
                    </td>
            <td valign="middle">
                <p>
                <a href="">
                    <papertitle>DFGC 2021: A DeepFake Game Competition</papertitle>
                </a>
                <br>
                Bo Peng, Hongxing Fan, Wei Wang, Jing Dong, <b>Yuezun Li</b>, Siwei Lyu, etc.
                <br>
                International Joint Conference on Biometrics (IJCB), 2021. 
                <br>
                <a href="">[Code]</a>               
                <br>
            </td>
        </tr>

        <tr>
            <td style="padding:10px;width:30%;vertical-align:middle;text-align:center;">
                <img src='images/df0m2021sp.png' width="150"></div>
                    </td>
            <td valign="middle">
                <p>
                <a href="">
                    <papertitle>DeepFake-o-meter: An Open Platform for DeepFake Detection</papertitle>
                </a>
                <br>
                <b>Yuezun Li</b>,Cong Zhang, Pu Sun, Lipeng Ke, Yan Ju, Honggang Qi, Siwei Lyu.
                <br>
                Systematic Approaches to Digital Forensic Engineering, in conjunction with the IEEE Security and Privacy Smposium (S&P), 2021. 
                <br>
                <a href="">[Code]</a>               
                <br>
            </td>
        </tr>
        </tbody></table>
        >> <a href="more_publications.html">More</a>
        <hr>

        <!--==========================================
                   fundings
        ===========================================-->
        <a name="Fundings"></a>
        <heading style="padding:10px">🏆 Fundings</heading>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
            <td style="padding:10px;width:100%;vertical-align:middle">
            <ul>
                <li>                    
                    <b>[2025-2027]</b>: PI, Young Scientists Fund of the Natural Science Foundation of Shandong Province. &nbsp; 
                    <span style="color:red">New!</span></b>
                </li> 
                <li>                    
                    <b>[2025-2027]</b>: PI, Young Scientists Fund of the National Natural Science Foundation of China. &nbsp; 
                    <span style="color:red">New!</span></b>
                </li>  
                <li>                    
                    <b>[2022-2023]</b>: PI, Fundamental Research Funds for the Central Universities. &nbsp;
                </li>  
                <li>                    
                    <b>[2022-2023]</b>: PI, Qingdao Postdoctoral Applied Research Project. &nbsp; </span>
                </li> 
                <li>                    
                    <b>[2021-2022]</b>: PI, CPSF 70-th Support. &nbsp; </span>
                </li>   
                <li>                    
                    <b>[2021-2022]</b>: PI, CPSF Special Support. &nbsp; </span>
                </li> 
            </ul>
          </td>
        </tr>
        </tbody></table>
        <hr>

        <!--==========================================
                   services
        ===========================================-->
        <a name="Service"></a>
        <heading style="padding:10px;">🚠 Service</heading>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
            <td style="padding:10px;width:100%;vertical-align:middle">
            <p>Journal Reviewer: 
                IEEE TIFS; IEEE TPAMI; IEEE TIP; IEEE TNNLS; IEEE JSTSP; IEEE TMM;
                IEEE TETCI; IJCV; IEEE TCSVT; Pattern Recognition
                </p>
                <p>Conference Reviewer: 
                CVPR; ICCV; ECCV; AAAI; NeurIPS; ICLR; BMVC
                </p>
          </td>
        </tr>
        </tbody></table>
        <hr>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td align="center">
                <a href='https://clustrmaps.com/site/1bcyj'  title='Visit tracker'><img src='//clustrmaps.com/map_v2.png?cl=ffffff&w=a&t=tt&d=OuDVjBphuIV15vb_K9-k4Nnidvdol9qiwaJ6-fy4sXQ'/></a>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>

<!-- Google Analytics -->
<!-- <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-131560165-1', 'auto');
  ga('send', 'pageview');
</script> -->
<!-- End Google Analytics -->

<script>
    const coll = document.querySelector(".collapsible");
    const content = document.querySelector(".content");

    coll.addEventListener("click", function() {
        content.style.display = content.style.display === "block" ? "none" : "block";
    });
</script>

</body>

</html>
